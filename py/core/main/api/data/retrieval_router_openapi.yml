search:
  openapi_extra:
    x-codeSamples:
      - lang: Python
        source: |
          from r2r import R2RClient

          client = R2RClient("http://localhost:7272")
          # when using auth, do client.login(...)

          result = client.search(
              query="Who is Aristotle?",
              vector_search_settings={
                  "use_vector_search": True,
                  "filters": {"document_id": {"eq": "3e157b3a-8469-51db-90d9-52e7d896b49b"}},
                  "search_limit": 20,
                  "use_hybrid_search": True
              },
              kg_search_settings={
                  "use_kg_search": True, # graph needs to be constructed first
                  "kg_search_type": "local",
                  "kg_search_level": "0",
                  "kg_search_generation_config": {
                      "model": "gpt-4o-mini",
                      "temperature": 0.7,
                  },
                  "local_search_limits": {
                      "__Entity__": 20,
                      "__Relationship__": 20,
                      "__Community__": 20,
                  },
                  "max_community_description_length": 65536,
                  "max_llm_queries_for_global_search": 250
              }
          )
      - lang: Shell
        source: |
          curl -X POST "https://api.example.com/search" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer YOUR_API_KEY" \
            -d '{
              "query": "Who is Aristotle?",
              "vector_search_settings": {
                "use_vector_search": true,
                "filters": {"document_id": {"eq": "3e157b3a-8469-51db-90d9-52e7d896b49b"}},
                "search_limit": 20,
                "use_hybrid_search": true
              },
              "kg_search_settings": {
                "use_kg_search": true, # graph needs to be constructed first
                "kg_search_type": "local",
                "kg_search_level": "0",
                "kg_search_generation_config": {
                    "model": "gpt-4o-mini",
                    "temperature": 0.7
                },
                "local_search_limits": {
                    "__Entity__": 20,
                    "__Relationship__": 20,
                    "__Community__": 20,
                },
                "max_community_description_length": 65536,
                "max_llm_queries_for_global_search": 250
              }
            }'

  input_descriptions:
    query: "Search query"
    vector_search_settings: "Vector search settings"
    kg_search_settings: "Knowledge graph search settings"

rag:
  openapi_extra:
    x-codeSamples:
      - lang: Python
        source: |
          from r2r import R2RClient

          client = R2RClient("http://localhost:7272")
          # when using auth, do client.login(...)

          result = client.rag(
              query="Who is Aristotle?",
              vector_search_settings={
                  "use_vector_search": True,
                  "filters": {"document_id": {"eq": "3e157b3a-8469-51db-90d9-52e7d896b49b"}},
                  "search_limit": 20,
                  "use_hybrid_search": True
              },
              kg_search_settings={
                  "use_kg_search": True,
                  "kg_search_type": "local",
                  "kg_search_level": "0",
                  "kg_search_generation_config": {
                      "model": "gpt-4o-mini",
                      "temperature": 0.7,
                  },
                  "local_search_limits": {
                      "__Entity__": 20,
                      "__Relationship__": 20,
                      "__Community__": 20,
                  },
                  "max_community_description_length": 65536,
                  "max_llm_queries_for_global_search": 250
              },
              rag_generation_config={
                  "stream": False,
                  "temperature": 0.7,
                  "max_tokens": 150
              }
          )
      - lang: Shell
        source: |
          curl -X POST "https://api.example.com/rag" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer YOUR_API_KEY" \
            -d '{
              "query": "Who is Aristotle?",
              "vector_search_settings": {
                "use_vector_search": true,
                "filters": {"document_id": {"eq": "3e157b3a-8469-51db-90d9-52e7d896b49b"}},
                "search_limit": 20,
                "use_hybrid_search": True
              },
              "kg_search_settings": {
                "use_kg_search": true, # graph needs to be constructed first
                "kg_search_type": "local",
                "kg_search_level": "0",
                "kg_search_generation_config": {
                    "model": "gpt-4o-mini",
                    "temperature": 0.7
                },
                "local_search_limits": {
                    "__Entity__": 20,
                    "__Relationship__": 20,
                    "__Community__": 20,
                },
                "max_community_description_length": 65536,
                "max_llm_queries_for_global_search": 250
              },
              "rag_generation_config": {
                "stream": false,
                "temperature": 0.7,
                "max_tokens": 150
              }
            }'

  input_descriptions:
    query: "RAG query"
    vector_search_settings: "Vector search settings"
    kg_search_settings: "Knowledge graph search settings"
    rag_generation_config: "RAG generation configuration"
    task_prompt_override: "Task prompt override"
    strategy: "The RAG strategy to use (default | HyDE | RAG Fusion)"
    include_title_if_available: "Includes document title in chunk response, if available."
    search_strategy: "The RAG strategy to use (default | hyde | rag_fusion)"

agent:
  openapi_extra:
    x-codeSamples:
      - lang: Python
        source: |
          from r2r import R2RClient

          client = R2RClient("http://localhost:7272")
          # when using auth, do client.login(...)

          result = client.agent(
              messages=[
                  {"role": "user", "content": "Who is the greatest philospher of all time?"},
                  {"role": "assistant", "content": "Aristotle is widely considered the greatest philospher of all time."},
                  {"role": "user", "content": "Can you tell me more about him?"}
              ],
              vector_search_settings={
                  "use_vector_search": True,
                  "filters": {"document_id": {"eq": "5e157b3a-8469-51db-90d9-52e7d896b49b"}},
                  "search_limit": 20,
                  "use_hybrid_search": True
              },
              rag_generation_config={
                  "stream": False,
                  "temperature": 0.7,
                  "max_tokens": 200
              },
              include_title_if_available=True
          )
      - lang: Shell
        source: |
          curl -X POST "https://api.example.com/agent" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer YOUR_API_KEY" \
            -d '{
              "messages": [
                {"role": "user", "content": "Who is the greatest philospher of all time?"},
                {"role": "assistant", "content": "Aristotle is widely considered the greatest philospher of all time."},
                {"role": "user", "content": "Can you tell me more about him?"}
              ],
              "vector_search_settings": {
                "use_vector_search": true,
                "filters": {"document_id": {"eq": "5e157b3a-8469-51db-90d9-52e7d896b49b"}},
                "search_limit": 20,
                "use_hybrid_search": true
              },
              "kg_search_settings": {
                "use_kg_search": false # to enable this, please read the graphrag cookbook
              },
              "rag_generation_config": {
                "stream": false,
                "temperature": 0.7,
                "max_tokens": 200
              },
              "include_title_if_available": true
            }'

  input_descriptions:
    messages: "List of message objects"
    vector_search_settings: "Vector search settings"
    kg_search_settings: "Knowledge graph search settings"
    rag_generation_config: "RAG generation configuration"
    task_prompt_override: "Task prompt override"
    include_title_if_available: "Includes document title in chunk response, if available."
    rag_strategy: "The RAG strategy to use (default | hyde | rag_fusion)"
