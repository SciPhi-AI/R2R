# A config which overrides all instances of `openai` with `azure` in the `r2r.toml` config
[agent]
  [agent.generation_config]
  model = "azure/gpt-4o"

[completion]
  [completion.generation_config]
  model = "azure/gpt-4o"



[database]
# KG settings
batch_size = 256

  [database.graph_creation_settings]
    generation_config = { model = "azure/gpt-4o-mini" }

  [database.graph_entity_deduplication_settings]
    generation_config = { model = "azure/gpt-4o-mini" }

  [database.graph_enrichment_settings]
    generation_config = { model = "azure/gpt-4o-mini" }

  [database.graph_search_settings]
    generation_config = { model = "azure/gpt-4o-mini" }

  [database.limits]
  global_per_min = 10  # Small enough to test quickly
  monthly_limit = 20  # Small enough to test in one run

  [database.route_limits]
  "/v3/retrieval/search" = { route_per_min = 5, monthly_limit = 10 }

  [database.user_limits."47e53676-b478-5b3f-a409-234ca2164de5"]
  global_per_min = 2
  route_per_min = 1


[embedding]
provider = "litellm"
base_model = "openai/text-embedding-3-small" # continue with `openai` for embeddings, due to server rate limit on azure
base_dimension = 512

[file]
provider = "postgres"

[ingestion]
provider = "r2r"
chunking_strategy = "recursive"
chunk_size = 1_024
chunk_overlap = 512
excluded_parsers = ["mp4"]

audio_transcription_model="azure/whisper-1"
document_summary_model = "azure/gpt-4o-mini"
vision_img_model = "azure/gpt-4o"
vision_pdf_model = "azure/gpt-4o"

  [ingestion.chunk_enrichment_settings]
    generation_config = { model = "azure/gpt-4o-mini" }
