# A config which overrides all instances of `openai` with `azure` in the `r2r.toml` config
[completion]
  [completion.generation_config]
  model = "azure/gpt-4o"

[agent]
  [agent.generation_config]
  model = "azure/gpt-4o"

# KG settings
batch_size = 256

  [database.kg_creation_settings]
    generation_config = { model = "azure/gpt-4o-mini" }

  [database.kg_entity_deduplication_settings]
    generation_config = { model = "azure/gpt-4o-mini" }

  [database.kg_enrichment_settings]
    generation_config = { model = "azure/gpt-4o-mini" }

  [database.kg_search_settings]
    generation_config = { model = "azure/gpt-4o-mini" }

[embedding]
provider = "litellm"
base_model = "openai/text-embedding-3-small" # continue with `openai` for embeddings, due to server rate limit on azure

[file]
provider = "postgres"

[ingestion]
provider = "unstructured_local"
strategy = "auto"
chunking_strategy = "by_title"
new_after_n_chars = 512
max_characters = 1_024
combine_under_n_chars = 128
overlap = 256
  [ingestion.extra_parsers]
    pdf = "zerox"

  [ingestion.chunk_enrichment_settings]
    generation_config = { model = "azure/gpt-4o-mini" }

[orchestration]
provider = "hatchet"
kg_creation_concurrency_lipmit = 32
ingestion_concurrency_limit = 128
kg_enrichment_concurrency_limit = 8
