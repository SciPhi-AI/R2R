---
title: 'Knowledge Graphs'
description: 'Creating a knowledge graph and running graphrag using R2R.'
---

## Create a graph

Creating a graph on your documents.


```python
client.create_graph(
    collection_id='122fdf6a-e116-546b-a8f6-e4cb2e2c0a09', # optional
    run_type="run", # estimate or run
    kg_creation_settings={
        "force_kg_creation": True,
        "kg_triples_extraction_prompt": "graphrag_triples_extraction_few_shot",
        "entity_types": [],
        "relation_types": [],
        "extraction_merge_count": 4,
        "max_knowledge_triples": 100,
        "max_description_input_length": 65536,
        "generation_config": {
            "model": "openai/gpt-4o-mini",
            # other generation config params
        }
    }
)
```

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="dict">
      The response from the R2R system after creating the graph.
      ```bash
      {'message': 'Graph creation task queued successfully.', 'task_id': '6e27dfca-606d-422d-b73f-2d9e138661b4'}
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>

<ParamField path="collection_id" type="Optional[Union[UUID, str]]">
  The ID of the collection to create the graph for. If not provided, the graph will be created for the default collection.
</ParamField>

<ParamField path="run_type" type="Optional[Union[str, KGRunType]]">
  The type of run to perform. Options are "estimate" or "run". Estimate will return an estimate of the creation cost, and run will create the graph.
</ParamField>


<ParamField path="kg_creation_settings" type="Optional[Union[dict, KGCreationSettings]]">
  The settings for the graph creation process.
  <Expandable title="KGCreationSettings">
    <ParamField path="kg_triples_extraction_prompt" type="str">
      The prompt to use for triples extraction.
    </ParamField>
    <ParamField path="entity_types" type="list[str]">
      The entity types to extract. If not provided, all entity types will be extracted.
    </ParamField>
    <ParamField path="relation_types" type="list[str]">
      The relation types to extract. If not provided, all relation types will be extracted.
    </ParamField>
    <ParamField path="extraction_merge_count" type="int">
      The number of chunks to merge into a single extraction.
    </ParamField>
    <ParamField path="max_knowledge_triples" type="int">
      The maximum number of triples to extract from each chunk.
    </ParamField>
    <ParamField path="max_description_input_length" type="int">
      The maximum length of the description for a node in the graph in characters (and not tokens).

      Used so that we don't hit the input context window of the LLM while generating descriptions.
    </ParamField>
    <ParamField path="generation_config" type="GenerationConfig">
      The configuration for text generation during graph enrichment.
    </ParamField>
  </Expandable>
</ParamField>

## Enrich a graph

```python
client.enrich_graph(
    collection_id='122fdf6a-e116-546b-a8f6-e4cb2e2c0a09',
    run_type="run",
    kg_enrichment_settings={
        "community_reports_prompt": "graphrag_community_reports",
        "max_summary_input_length": 65536,
        "generation_config": {
            "model": "openai/gpt-4o-mini",
            "temperature": 0.12,
            # other generation config params
        },
        "leiden_params": {
            # leiden algorithm params, all are optional, default values are shown
            "max_cluster_size": 1000,
            "starting_communities": None,
            "extra_forced_iterations": 0,
            "resolution": 1.0,
            "randomness": 0.001,
            "use_modularity": True,
            "random_seed": 7272, # If not set, defaults to 7272
            "weight_attribute": "weight",
            "is_weighted": None,
            "weight_default": 1.0,
            "check_directed": True,
        }
    }
)
```

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="dict">
      The response from the R2R system after enriching the graph.
      ```bash
      {'message': 'Graph enrichment task queued successfully.', 'task_id': '6e27dfca-606d-422d-b73f-2d9e138661b4'}
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>


<ParamField path="collection_id" type="Optional[Union[UUID, str]]">
  The ID of the collection to enrich the graph for. If not provided, the graph will be enriched for the default collection.
</ParamField>

<ParamField path="run_type" type="Optional[Union[str, KGRunType]]">
  The type of run to perform. Options are "estimate" or "run". Estimate will return an estimate of the enrichment cost, and run will create the enriched graph.
</ParamField>

<ParamField path="kg_enrichment_settings" type="Optional[Union[dict, KGEnrichmentSettings]]">
  The settings for the graph enrichment process.
  <Expandable title="KGEnrichmentSettings">
    <ParamField path="community_reports_prompt" type="str">
      The prompt to use for community reports.
    </ParamField>
    <ParamField path="max_summary_input_length" type="int">
      The maximum length of the summary input in characters (and not tokens).

      Used so that we don't hit the input context window of the LLM while generating community summaries.
    </ParamField>
    <ParamField path="generation_config" type="GenerationConfig">
      The configuration for text generation during graph enrichment.
    </ParamField>
    <ParamField path="leiden_params" type="dict">
      The parameters for the Leiden algorithm.
      <Expandable title="LeidenParams">
        <ParamField path="max_cluster_size" type="int">
          Default is ``1000``. Any partition or cluster with
          membership >= ``max_cluster_size`` will be isolated into a subnetwork. This
          subnetwork will be used for a new leiden global partition mapping, which will
          then be remapped back into the global space after completion. Once all
          clusters with membership >= ``max_cluster_size`` have been completed, the level
          increases and the partition scheme is scanned again for any new clusters with
          membership >= ``max_cluster_size`` and the process continues until every
          cluster's membership is < ``max_cluster_size`` or if they cannot be broken into
          more than one new community.

        </ParamField>
        <ParamField path="starting_communities" type="Optional[Dict[Any, int]]">
          Default is ``None``. An optional community mapping dictionary that contains a node
          id mapping to the community it belongs to. Please see the Notes section regarding
          node ids used.

          If no community map is provided, the default behavior is to create a node
          community identity map, where every node is in their own community.
        </ParamField>
        <ParamField path="extra_forced_iterations" type="int">
          Default is ``0``. Leiden will run until a maximum quality score has been found
          for the node clustering and no nodes are moved to a new cluster in another
          iteration. As there is an element of randomness to the Leiden algorithm, it is
          sometimes useful to set ``extra_forced_iterations`` to a number larger than 0
          where the entire process is forced to attempt further refinement.
        </ParamField>
        <ParamField path="resolution" type="Union[int, float]">
                Default is ``1.0``. Higher resolution values lead to more communities and lower
        resolution values leads to fewer communities. Must be greater than 0.

        </ParamField>
        <ParamField path="randomness" type="Union[int, float]">
        Default is ``0.001``. The larger the randomness value, the more exploration of
        the partition space is possible. This is a major difference from the Louvain
        algorithm, which is purely greedy in the partition exploration.
        </ParamField>
        <ParamField path="use_modularity" type="bool">
        Default is ``True``. If ``False``, will use a Constant Potts Model (CPM).
        </ParamField>
        <ParamField path="random_seed" type="Optional[int]">
        Default is ``7272``. Can provide an optional seed to the PRNG used in Leiden
        for deterministic output.
        </ParamField>
        <ParamField path="weight_attribute" type="str">
        Default is ``weight``. Only used when creating a weighed edge list of tuples
        when the source graph is a networkx graph. This attribute corresponds to the
        edge data dict key.
        </ParamField>
        <ParamField path="is_weighted" type="Optional[bool]">
        Default is ``None``. Only used when creating a weighted edge list of tuples
        when the source graph is an adjacency matrix. The
        :func:`graspologic.utils.is_unweighted` function will scan these
        matrices and attempt to determine whether it is weighted or not. This flag can
        short circuit this test and the values in the adjacency matrix will be treated
        as weights.
        </ParamField>
        <ParamField path="weight_default" type="Union[int, float]">
        Default is ``1.0``. If the graph is a networkx graph and the graph does not
        have a fully weighted sequence of edges, this default will be used. If the
        adjacency matrix is found or specified to be unweighted, this weight_default
        will be used for every edge.
        </ParamField>
        <ParamField path="check_directed" type="bool">
        Default is ``True``. If the graph is an adjacency matrix, we will attempt to
        ascertain whether it is directed or undirected. As our leiden implementation is
        only known to work with an undirected graph, this function will raise an error
        if it is found to be a directed graph. If you know it is undirected and wish to
        avoid this scan, you can set this value to ``False`` and only the lower triangle
        of the adjacency matrix will be used to generate the weighted edge list.
        </ParamField>
      </Expandable>
    </ParamField>
  </Expandable>
</ParamField>

## Get entities

```python
client.get_entities(
  collection_id='122fdf6a-e116-546b-a8f6-e4cb2e2c0a09',
  offset=0,
  limit=1000,
  entity_ids=None
)
```

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="dict">
      The response from the R2R system containing the list of entities in the graph. Total entries is the total number of entities in the graph for the collection (not the number of entities returned).
      ```bash
      {
        "results": {
          "entities": [
            {
              "name": "PLATO",
              "id": 2,
              "category": null,
              "description": "Plato was a prominent philosopher in ancient Greece, known for his foundational role in Western philosophy and for being the teacher of Aristotle at the Academy in Athens. His teachings significantly influenced Aristotle, who later established the Lyceum, reflecting the enduring impact of Plato's philosophical ideas on subsequent educational institutions.",
              "description_embedding": null,
              "community_numbers": null,
              "extraction_ids": [
                "91370d27-31a4-5f6e-8a0c-2c943680fd78",
                "695fa5b3-e416-5608-ba52-3b8b0a66bf3a",
                "85e39f16-26b8-5fd3-89be-e9592864bb46",
                "42c9e012-08e4-54d5-8df9-a8cb9fe277c9"
              ],
              "collection_id": null,
              "document_id": "32b6a70f-a995-5c51-85d2-834f06283a1e",
              "attributes": null
            },
            ... # more entities
          ],
          "total_entries": 2
        }
      }
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>

<ParamField path="collection_id" type="Optional[Union[UUID, str]]">
  The ID of the collection to get the entities from. If not provided, the entities will be retrieved from the default collection.
</ParamField>

<ParamField path="offset" type="int">
  The offset for pagination.
</ParamField>


<ParamField path="limit" type="int">
  The limit for pagination.
</ParamField>

<ParamField path="entity_ids" type="Optional[list[str]]">
  The list of entity IDs to filter by.
</ParamField>

## Get triples

```python
client.get_triples(
  collection_id='122fdf6a-e116-546b-a8f6-e4cb2e2c0a09',
  offset=0,
  limit=100,
  entity_names=[],
  triple_ids=None
)
```

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="dict">
      The response from the R2R system containing the list of triples in the graph. Total entries is the total number of triples in the graph for the collection (not the number of triples returned).

      ```bash
      {
        'results': {
          'total_entries': 28,
          'triples': [
            {
              'id': 1,
              'subject': 'ARISTOTLE',
              'predicate': 'Father-Son',
              'object': 'NICOMACHUS',
              'weight': 1.0,
              'description': 'Nicomachus was the father of Aristotle, who died when Aristotle was a child. ',
              'predicate_embedding': None,
              'extraction_ids': [],
              'document_id': None,
              'attributes': {}
            },
            ... # more triples
          ]
        }
      }
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>


<ParamField path="collection_id" type="Optional[Union[UUID, str]]">
  The ID of the collection to get the triples from. If not provided, the triples will be retrieved from the default collection.
</ParamField>

<ParamField path="offset" type="Optional[int]">
  The offset for pagination. Defaults to 0.
</ParamField>


<ParamField path="limit" type="Optional[int]">
  The limit for pagination. Defaults to 100.
</ParamField>

<ParamField path="entity_names" type="Optional[list[str]]">
  The list of entity names to filter by. Entities are in all caps. eg. ['ARISTOTLE', 'PLATO']
</ParamField>

<ParamField path="triple_ids" type="Optional[list[str]]">
  The list of triple IDs to filter by.
</ParamField>


## Get Communities

```python
client.get_communities(
  collection_id='122fdf6a-e116-546b-a8f6-e4cb2e2c0a09',
  offset=0,
  limit=100,
  levels=[],
  community_numbers=[],
)
```

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="dict">
      The response from the R2R system containing the list of communities in the graph.

      ```bash
      {
        'results':
          {
            'communities': [
            {
              'community_number': 0,
              'level': 0,
              'collection_id': '122fdf6a-e116-546b-a8f6-e4cb2e2c0a09',
              'name': "Aristotle and Plato's Legacy",
              'summary': "This community encompasses key historical figures and institutions such as Aristotle, Plato, and their respective schools, Plato's Academy and the Lyceum. The interconnected relationships highlight the profound influence these entities have had on Western philosophy, education, and intellectual traditions.",
              'findings':
                [
                  "Aristotle, a polymath and philosopher, significantly contributed to various fields including natural sciences and ethics, and his teachings have had a lasting impact on medieval scholarship and modern philosophy. His role as a tutor to Alexander the Great further emphasizes his influence on historical leadership and governance. [Data: Entities (11), Relationships (3, 8, 22, +more)]",
                  "Plato's Academy served as a critical educational institution where Aristotle studied for 20 years, shaping his intellectual development and laying the groundwork for his later contributions to philosophy. The Academy's legacy is marked by its role in fostering critical thought and dialogue in ancient philosophy. [Data: Entities (5), Relationships (2, 17, 26, +more)]",
                  "The Lyceum, founded by Aristotle, became a vital source of knowledge and a hub for philosophical discourse in ancient Athens, influencing both medieval scholarship and the development of Western educational practices. Its establishment marked a significant evolution in the teaching of philosophy. [Data: Entities (7), Relationships (4, 11, 25, +more)]",
                  "Stagira, the birthplace of Aristotle, holds historical significance as a cultural landmark that contributed to the intellectual legacy of Aristotle and, by extension, Western philosophy. This connection underscores the importance of geographical context in the development of philosophical thought. [Data: Entities (3), Relationships (6, +more)]",
                  "The influence of Plato on Aristotle's teachings is evident in the establishment of the Lyceum, which reflects the enduring impact of Plato's philosophical ideas on subsequent educational institutions and the evolution of Western philosophy. [Data: Entities (2), Relationships (13, 26, +more)]"
                ],
                'rating': 9.5,
                'rating_explanation': 'The impact severity rating is exceptionally high due to the foundational role these philosophers and their teachings have played in shaping Western thought and educational systems.',
                'embedding': None,
                'attributes': None
            },
            ... # more communities
          ],
          'total_entries': 3
        }
      }
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>

<ParamField path="collection_id" type="Optional[Union[UUID, str]]">
  The ID of the collection to get the communities from. If not provided, the communities will be retrieved from the default collection.
</ParamField>

<ParamField path="offset" type="Optional[int]">
  The offset for pagination. Defaults to 0.
</ParamField>


<ParamField path="limit" type="Optional[int]">
  The limit for pagination. Defaults to 100.
</ParamField>


<ParamField path="levels" type="Optional[list[int]]">
  The list of levels to filter by. As output of hierarchical clustering, each community is assigned a level.
</ParamField>


<ParamField path="community_numbers" type="Optional[list[int]]">
  The list of community numbers to filter by.
</ParamField>

## Delete Graph

Delete the graph for a collection using the `delete_graph_for_collection` method.

```python
client.delete_graph_for_collection(
  collection_id='122fdf6a-e116-546b-a8f6-e4cb2e2c0a09',
  cascade=False
)
```

<ParamField path="collection_id" type="Union[UUID, str]">
  The ID of the collection to delete the graph for.
</ParamField>

<ParamField path="cascade" type="bool">
  Whether to cascade the deletion.

  NOTE: Setting this flag to true will delete entities and triples for documents that are shared across multiple collections. Do not set this flag unless you are absolutely sure that you want to delete the entities and triples for all documents in the collection.
</ParamField>

## Get Tuned Prompt

```python
client.get_tuned_prompt(
    prompt_name="graphrag_entity_description",
    collection_id='122fdf6a-e116-546b-a8f6-e4cb2e2c0a09',
    documents_offset=0,
    documents_limit=100,
    chunk_offset=0,
    chunk_limit=100
)
```

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="dict">
      The response containing the tuned prompt for GraphRAG.
      ```bash
      {
        "results": {
          "tuned_prompt": "string"
        }
      }
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>

<ParamField path="prompt_name" type="str">
  The name of the prompt to tune. Valid values include "graphrag_entity_description", "graphrag_triples_extraction_few_shot", and "graphrag_community_reports".
</ParamField>

<ParamField path="collection_id" type="Optional[Union[UUID, str]]">
  The ID of the collection to tune the prompt for. If not provided, the default collection will be used.
</ParamField>

<ParamField path="documents_offset" type="Optional[int]">
  The offset for pagination of documents. Defaults to 0.
</ParamField>

<ParamField path="documents_limit" type="Optional[int]">
  The limit for pagination of documents. Defaults to 100. Controls how many documents are used for tuning.
</ParamField>

<ParamField path="chunk_offset" type="Optional[int]">
  The offset for pagination of chunks within each document. Defaults to 0.
</ParamField>

<ParamField path="chunk_limit" type="Optional[int]">
  The limit for pagination of chunks within each document. Defaults to 100. Controls how many chunks per document are used for tuning.
</ParamField>

The tuning process provides an LLM with chunks from each document in the collection. The relative sample size can therefore be controlled by adjusting the document and chunk limits.


## Search and RAG

Please see the [Search and RAG](/documentation/python-sdk/retrieval) documentation for more information on how to perform search and RAG using Knowledge Graphs.

## API Reference

Please see the [API documentation](/api-reference/endpoint/create_graph) for more information on the capabilities of the R2R Graph creation and enrichment API.
