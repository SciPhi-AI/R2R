---
title: 'Ingestion'
description: 'Ingesting files with R2R.'
---

<Note>
This SDK documentation is periodically updated. For the latest parameter details, please cross-reference with the <a href="/api-reference/introduction">API Reference documentation</a>.
</Note>

Inside R2R, `ingestion` refers to the complete pipeline for processing input data:
- Parsing files into text
- Chunking text into semantic units
- Generating embeddings
- Storing data for retrieval

Ingested files are stored with an associated document identifier as well as a user identifier to enable comprehensive management.

## Document Ingestion and Management

<Note>

R2R has recently expanded the available options for ingesting files using multimodal foundation models. In addition to using such models by default for images, R2R can now use them on PDFs, [like it is shown here](https://github.com/getomni-ai/zerox), by passing the following in your ingestion configuration:

```json
"ingestion_config": {
  ...,
  "parser_overrides": {
    "pdf": "zerox"
  }
}
```

We recommend this method for achieving the highest quality ingestion results.

</Note>

### Ingest Files



Ingest files or directories into your R2R system:

```python
file_paths = ['path/to/file1.txt', 'path/to/file2.txt']
metadatas = [{'key1': 'value1'}, {'key2': 'value2'}]

# Ingestion configuration for `R2R Full`
ingest_response = client.ingest_files(
    file_paths=file_paths,
    metadatas=metadatas,
    # Runtime chunking configuration
    ingestion_config={
        "provider": "unstructured_local",  # Local processing
        "strategy": "auto",                # Automatic processing strategy
        "chunking_strategy": "by_title",   # Split on title boundaries
        "new_after_n_chars": 256,         # Start new chunk (soft limit)
        "max_characters": 512,            # Maximum chunk size (hard limit)
        "combine_under_n_chars": 64,      # Minimum chunk size
        "overlap": 100,                   # Character overlap between chunks
    }
)
```

An `ingested` file is parsed, chunked, embedded and stored inside your R2R system. The stored information includes a document identifier, a corresponding user identifier, and other metadata. Knowledge graph creation is done separately and at the `collection` level. Refer to the [ingestion configuration](/documentation/configuration/ingestion/parsing_and_chunking) section for comprehensive details on available options.

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="dict">
      The response from the R2R system after ingesting the files.
      ```bash
      [{'message': 'Ingestion task queued successfully.', 'task_id': '6e27dfca-606d-422d-b73f-2d9e138661b4', 'document_id': 'c3291abf-8a4e-5d9d-80fd-232ef6fd8526'}, ...]
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>

<ParamField path="file_paths" type="list[str]" required>
  A list of file paths or directory paths to ingest. If a directory path is provided, all files within the directory and its subdirectories will be ingested.
</ParamField>

<ParamField path="metadatas" type="Optional[list[dict]]">
  An optional list of metadata dictionaries corresponding to each file. If provided, the length should match the number of files being ingested.
</ParamField>

<ParamField path="document_ids" type="Optional[list[Union[UUID, str]]]">
  An optional list of document IDs to assign to the ingested files. If provided, the length should match the number of files being ingested.
</ParamField>

<ParamField path="versions" type="Optional[list[str]]">
  An optional list of version strings for the ingested files. If provided, the length should match the number of files being ingested.
</ParamField>


<ParamField path="ingestion_config" type="Optional[Union[dict, IngestionConfig]]">
  The ingestion config override parameter enables developers to customize their R2R chunking strategy at runtime. Learn more about [configuration here](/documentation/configuration/ingestion/parsing_and_chunking).
  <Expandable title="Other Provider Options">
    <ParamField path="provider" type="str" default="r2r">
      Which R2R ingestion provider to use. Options are "r2r".
    </ParamField>
    <ParamField path="chunking_strategy" type="str" default="recursive">
      Only `recursive` is currently supported.
    </ParamField>
    <ParamField path="chunk_size" type="number" default="1_024">
      The target size for output chunks.
    </ParamField>
    <ParamField path="chunk_overlap" type="number" default="512">
      The target overlap fraction for output chunks
    </ParamField>
    <ParamField path="parser_overrides" type="dict[str, str]" >
      Dictionary of filetypes and selected override parsers. Currently only `{"pdf": "zerox"}` is supported.
    </ParamField>
  </Expandable>

  <Expandable title="Unstructured Provider Options">
    <ParamField path="provider" type="str" default="unstructured_local">
      Which unstructured ingestion provider to use. Options are "unstructured_local", or "unstructured_api".
    </ParamField>

    <ParamField path="parser_overrides" type="dict[str, str]" >
      Dictionary of filetypes and selected override parsers. Currently only `{"pdf": "zerox"}` is supported.
    </ParamField>

    <ParamField path="max_chunk_size" type="Optional[int]" default="None">
      Sets a maximum size on output chunks.
    </ParamField>

    <ParamField path="combine_under_n_chars" type="Optional[int]">
      Combine chunks smaller than this number of characters.
    </ParamField>

    <ParamField path="max_characters" type="Optional[int]">
      Maximum number of characters per chunk.
    </ParamField>

    <ParamField path="coordinates" type="bool" default="False">
      Whether to include coordinates in the output.
    </ParamField>

    <ParamField path="encoding" type="Optional[str]">
      Encoding to use for text files.
    </ParamField>

    <ParamField path="extract_image_block_types" type="Optional[list[str]]">
      Types of image blocks to extract.
    </ParamField>

    <ParamField path="gz_uncompressed_content_type" type="Optional[str]">
      Content type for uncompressed gzip files.
    </ParamField>

    <ParamField path="hi_res_model_name" type="Optional[str]">
      Name of the high-resolution model to use.
    </ParamField>

    <ParamField path="include_orig_elements" type="Optional[bool]" default="False">
      Whether to include original elements in the output.
    </ParamField>

    <ParamField path="include_page_breaks" type="bool">
      Whether to include page breaks in the output.
    </ParamField>

    <ParamField path="languages" type="Optional[list[str]]">
      List of languages to consider for text processing.
    </ParamField>

    <ParamField path="multipage_sections" type="bool" default="True">
      Whether to allow sections to span multiple pages.
    </ParamField>

    <ParamField path="new_after_n_chars" type="Optional[int]">
      Start a new chunk after this many characters.
    </ParamField>

    <ParamField path="ocr_languages" type="Optional[list[str]]">
      Languages to use for OCR.
    </ParamField>

    <ParamField path="output_format" type="str" default="application/json">
      Format of the output.
    </ParamField>

    <ParamField path="overlap" type="int" default="0">
      Number of characters to overlap between chunks.
    </ParamField>

    <ParamField path="overlap_all" type="bool" default="False">
      Whether to overlap all chunks.
    </ParamField>

    <ParamField path="pdf_infer_table_structure" type="bool" default="True">
      Whether to infer table structure in PDFs.
    </ParamField>

    <ParamField path="similarity_threshold" type="Optional[float]">
      Threshold for considering chunks similar.
    </ParamField>

    <ParamField path="skip_infer_table_types" type="Optional[list[str]]">
      Types of tables to skip inferring.
    </ParamField>

    <ParamField path="split_pdf_concurrency_level" type="int" default="5">
      Concurrency level for splitting PDFs.
    </ParamField>

    <ParamField path="split_pdf_page" type="bool" default="True">
      Whether to split PDFs by page.
    </ParamField>

    <ParamField path="starting_page_number" type="Optional[int]">
      Page number to start processing from.
    </ParamField>

    <ParamField path="strategy" type="str" default="auto">
      Strategy for processing. Options are "auto", "fast", or "hi_res".
    </ParamField>

    <ParamField path="chunking_strategy" type="Optional[str]" default="by_title">
      Strategy for chunking. Options are "by_title" or "basic".
    </ParamField>

    <ParamField path="unique_element_ids" type="bool" default="False">
      Whether to generate unique IDs for elements.
    </ParamField>

    <ParamField path="xml_keep_tags" type="bool" default="False">
      Whether to keep XML tags in the output.
    </ParamField>
  </Expandable>

  <ParamField path="run_with_orchestration" type="Optional[bool]">
    Whether or not ingestion runs with [orchestration](/cookbooks/orchestration), default is `True`. When set to `False`, the ingestion process will run synchronous and directly return the result.
  </ParamField>


</ParamField>

### Understanding Ingestion Status

After calling `ingest_files`, the response includes important status information:

```python
# Successful ingestion
{
    'message': 'Ingestion task queued successfully.',
    'task_id': '6e27dfca-606d-422d-b73f-2d9e138661b4',
    'document_id': 'c3291abf-8a4e-5d9d-80fd-232ef6fd8526'
}

# Check document status later
doc_status = client.documents_overview(
    document_ids=['c3291abf-8a4e-5d9d-80fd-232ef6fd8526']
)
# ingestion_status will be one of: 'pending', 'processing', 'success', 'failed'
```

### Ingest Chunks

The `ingest_chunks` method allows direct ingestion of pre-processed text, bypassing the standard parsing pipeline. This is useful for:
- Custom preprocessing pipelines
- Streaming data ingestion
- Working with non-file data sources

```python
chunks = [
  {
    "text": "Aristotle was a Greek philosopher...",
  },
  ...,
  {
    "text": "He was born in 384 BC in Stagira...",
  }
]

ingest_response = client.ingest_chunks(
  chunks=chunks,
  metadata={"title": "Aristotle", "source": "wikipedia"}
)
```

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="dict">
      The response from the R2R system after ingesting the chunks.
      ```bash
      {'message': 'Ingest chunks task queued successfully.', 'task_id': '8f27dfca-606d-422d-b73f-2d9e138661c3', 'document_id': 'd4391abf-8a4e-5d9d-80fd-232ef6fd8527'}
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>

<ParamField path="chunks" type="list[dict]" required>
  A list of chunk dictionaries to ingest. Each dictionary should contain at least a "text" key with the chunk text. An optional "metadata" key can contain a dictionary of metadata for the chunk.
</ParamField>

<ParamField path="document_id" type="Optional[UUID]">
  An optional document ID to assign to the ingested chunks. If not provided, a new document ID will be generated.
</ParamField>

<ParamField path="metadata" type="Optional[dict]">
  An optional metadata dictionary for the document.
</ParamField>

<ParamField path="run_with_orchestration" type="Optional[bool]">
  Whether or not ingestion runs with [orchestration](/cookbooks/orchestration), default is `True`. When set to `False`, the ingestion process will run synchronous and directly return the result.
</ParamField>


### Update Files

Update existing documents while maintaining version history:

```python
# Basic update with new metadata
update_response = client.update_files(
    file_paths=file_paths,
    document_ids=document_ids,
    metadatas=[{
        "status": "reviewed"
    }]
)

# Update with custom chunking
update_response = client.update_files(
    file_paths=file_paths,
    document_ids=document_ids,
    ingestion_config={
        "chunking_strategy": "by_title",
        "max_characters": 1024  # Larger chunks for this version
    }
)
```

The ingestion configuration can be customized analogously to the ingest files endpoint above.
<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="dict">
      The response from the R2R system after updating the files.
      ```bash
      [{'message': 'Update files task queued successfully.', 'task_id': '6e27dfca-606d-422d-b73f-2d9e138661b4', 'document_id': '9f375ce9-efe9-5b57-8bf2-a63dee5f3621'}, ...]
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>

<ParamField path="file_paths" type="list[str]" required>
  A list of file paths to update.
</ParamField>

<ParamField path="document_ids" type="Optional[list[Union[UUID, str]]]" required>
  A list of document IDs corresponding to the files being updated. When not provided, an attempt is made to generate the correct document id from the given user id and file path.
</ParamField>

<ParamField path="metadatas" type="Optional[list[dict]]">
  An optional list of metadata dictionaries for the updated files.
</ParamField>


<ParamField path="ingestion_config" type="Optional[Union[dict, IngestionConfig]]">
  The ingestion config override parameter enables developers to customize their R2R chunking strategy at runtime. Learn more about [configuration here](/documentation/configuration/ingestion/parsing_and_chunking).
  <Expandable title="Other Provider Options">
    <ParamField path="provider" type="str" default="r2r">
      Which R2R ingestion provider to use. Options are "r2r".
    </ParamField>
    <ParamField path="chunking_strategy" type="str" default="recursive">
      Only `recursive` is currently supported.
    </ParamField>
    <ParamField path="chunk_size" type="number" default="1_024">
      The target size for output chunks.
    </ParamField>
    <ParamField path="chunk_overlap" type="number" default="512">
      The target overlap fraction for output chunks
    </ParamField>
    <ParamField path="parser_overrides" type="dict[str, str]" >
      Dictionary of filetypes and selected override parsers. Currently only `{"pdf": "zerox"}` is supported.
    </ParamField>
  </Expandable>

  <Expandable title="Unstructured Provider Options">
    <ParamField path="provider" type="str" default="unstructured_local">
      Which unstructured ingestion provider to use. Options are "unstructured_local", or "unstructured_api".
    </ParamField>

    <ParamField path="max_chunk_size" type="Optional[int]" default="None">
      Sets a maximum size on output chunks.
    </ParamField>

    <ParamField path="combine_under_n_chars" type="Optional[int]">
      Combine chunks smaller than this number of characters.
    </ParamField>

    <ParamField path="max_characters" type="Optional[int]">
      Maximum number of characters per chunk.
    </ParamField>

    <ParamField path="coordinates" type="bool" default="False">
      Whether to include coordinates in the output.
    </ParamField>

    <ParamField path="encoding" type="Optional[str]">
      Encoding to use for text files.
    </ParamField>

    <ParamField path="extract_image_block_types" type="Optional[list[str]]">
      Types of image blocks to extract.
    </ParamField>

    <ParamField path="gz_uncompressed_content_type" type="Optional[str]">
      Content type for uncompressed gzip files.
    </ParamField>

    <ParamField path="hi_res_model_name" type="Optional[str]">
      Name of the high-resolution model to use.
    </ParamField>

    <ParamField path="include_orig_elements" type="Optional[bool]" default="False">
      Whether to include original elements in the output.
    </ParamField>

    <ParamField path="include_page_breaks" type="bool">
      Whether to include page breaks in the output.
    </ParamField>

    <ParamField path="languages" type="Optional[list[str]]">
      List of languages to consider for text processing.
    </ParamField>

    <ParamField path="multipage_sections" type="bool" default="True">
      Whether to allow sections to span multiple pages.
    </ParamField>

    <ParamField path="new_after_n_chars" type="Optional[int]">
      Start a new chunk after this many characters.
    </ParamField>

    <ParamField path="ocr_languages" type="Optional[list[str]]">
      Languages to use for OCR.
    </ParamField>

    <ParamField path="output_format" type="str" default="application/json">
      Format of the output.
    </ParamField>

    <ParamField path="overlap" type="int" default="0">
      Number of characters to overlap between chunks.
    </ParamField>

    <ParamField path="overlap_all" type="bool" default="False">
      Whether to overlap all chunks.
    </ParamField>

    <ParamField path="pdf_infer_table_structure" type="bool" default="True">
      Whether to infer table structure in PDFs.
    </ParamField>

    <ParamField path="similarity_threshold" type="Optional[float]">
      Threshold for considering chunks similar.
    </ParamField>

    <ParamField path="skip_infer_table_types" type="Optional[list[str]]">
      Types of tables to skip inferring.
    </ParamField>

    <ParamField path="split_pdf_concurrency_level" type="int" default="5">
      Concurrency level for splitting PDFs.
    </ParamField>

    <ParamField path="split_pdf_page" type="bool" default="True">
      Whether to split PDFs by page.
    </ParamField>

    <ParamField path="starting_page_number" type="Optional[int]">
      Page number to start processing from.
    </ParamField>

    <ParamField path="strategy" type="str" default="auto">
      Strategy for processing. Options are "auto", "fast", or "hi_res".
    </ParamField>

    <ParamField path="chunking_strategy" type="Optional[str]" default="by_title">
      Strategy for chunking. Options are "by_title" or "basic".
    </ParamField>

    <ParamField path="unique_element_ids" type="bool" default="False">
      Whether to generate unique IDs for elements.
    </ParamField>

    <ParamField path="xml_keep_tags" type="bool" default="False">
      Whether to keep XML tags in the output.
    </ParamField>
  </Expandable>

  <ParamField path="run_with_orchestration" type="Optional[bool]">
    Whether or not ingestion runs with orchestration, default is `True`. When set to `False`, the ingestion process will run synchronous and directly return the result.
  </ParamField>
</ParamField>


### Documents Overview

Retrieve high-level document information. Results are restricted to the current user's files, unless the request is made by a superuser, in which case results from all users are returned:

```python
documents_overview = client.documents_overview()
```

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="list[dict]">
      A list of dictionaries containing document information.
      ```bash
      [
        {
          'document_id': '9fbe403b-c11c-5aae-8ade-ef22980c3ad1',
          'version': 'v0',
          'collection_ids': [],
          'ingestion_status': 'success',
          'restructuring_status': 'pending',
          'user_id': '2acb499e-8428-543b-bd85-0d9098718220',
          'title': 'aristotle.txt',
          'created_at': '2024-07-21T20:09:14.218741Z',
          'updated_at': '2024-07-21T20:09:14.218741Z',
          'metadata': {'title': 'aristotle.txt', 'version': 'v0', 'x': 'y'}
        },
        ...
      ]
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>

<ParamField path="document_ids" type="Optional[list[Union[UUID, str]]]">
  An optional list of document IDs to filter the overview.
</ParamField>
<ParamField path="offset" type="Optional[int]">
  An optional value to offset the starting point of fetched results, defaults to `0`.
</ParamField>
<ParamField path="limit" type="Optional[int]">
  An optional value to limit the fetched results, defaults to `100`.
</ParamField>


### Document Chunks

Fetch and examine chunks for a particular document. Chunks represent the atomic units of text after processing:

```python
document_id = "9fbe403b-c11c-5aae-8ade-ef22980c3ad1"
chunks = client.document_chunks(document_id)
```

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="list[dict]">
      A list of dictionaries containing chunk information.
      ```bash
      [
        {
          'text': 'Aristotle[A] (Greek: Ἀριστοτέλης Aristotélēs, pronounced [aristotélɛːs]; 384–322 BC) was an Ancient Greek philosopher and polymath...',
          'user_id': '2acb499e-8428-543b-bd85-0d9098718220',
          'document_id': '9fbe403b-c11c-5aae-8ade-ef22980c3ad1',
          'extraction_id': 'aeba6400-1bd0-5ee9-8925-04732d675434',
          'fragment_id': 'f48bcdad-4155-52a4-8c9d-8ba06e996ba3'
          'metadata': {'title': 'aristotle.txt', 'version': 'v0', 'chunk_order': 0, 'document_type': 'txt', 'unstructured_filetype': 'text/plain', 'unstructured_languages': ['eng'], 'unstructured_parent_id': '971399f6ba2ec9768d2b5b92ab9d17d6', 'partitioned_by_unstructured': True}
        },
        ...
      ]
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>


<ParamField path="document_id" type="str" required>
  The ID of the document to retrieve chunks for.
</ParamField>
<ParamField path="offset" type="Optional[int]">
  An optional value to offset the starting point of fetched results, defaults to `0`.
</ParamField>
<ParamField path="limit" type="Optional[int]">
  An optional value to limit the fetched results, defaults to `100`.
</ParamField>
<ParamField path="include_vectors" type="Optional[bool]">
  An optional value to return the vectors associated with each chunk, defaults to `False`.
</ParamField>


### Delete Documents

Delete a document by its ID:

```python
delete_response = client.delete(
  {
    "document_id":
      {"$eq": "9fbe403b-c11c-5aae-8ade-ef22980c3ad1"}
  }
)
```

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="dict">
      The response from the R2R system after successfully deleting the documents.
      ```bash
      {'results': {}}
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>

<ParamField path="filters" type="list[dict]" required>
  A list of logical filters to perform over input documents fields which identifies the unique set of documents to delete (e.g., `{"document_id": {"$eq": "9fbe403b-c11c-5aae-8ade-ef22980c3ad1"}}`). Logical operations might include variables such as `"user_id"` or  `"title"` and filters like `neq`, `gte`, etc.
</ParamField>


## Vector Index Management

### Create Vector Index

<Note>
Vector indices significantly improve search performance for large collections but add overhead for smaller datasets. Only create indices when working with hundreds of thousands of documents or when search latency is critical.
</Note>

Create a vector index for similarity search:


```python
create_response = client.create_vector_index(
    table_name="vectors",
    index_method="hnsw",
    index_measure="cosine_distance",
    index_arguments={"m": 16, "ef_construction": 64},
    concurrently=True
)
```

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="dict">
      The response from the R2R system after creating the vector index.
      ```bash
      {
        'message': 'Vector index creation task queued successfully.',
        'task_id': '7d38dfca-606d-422d-b73f-2d9e138661b5'
      }
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>

<ParamField path="table_name" type="str">
  The table to create the index on. Options: vectors, entities_document, entities_collection, communities. Default: vectors
</ParamField>

<ParamField path="index_method" type="str">
  The indexing method to use. Options: hnsw, ivfflat, auto. Default: hnsw
</ParamField>

<ParamField path="index_measure" type="str">
  Distance measure for vector comparisons. Options: cosine_distance, l2_distance, max_inner_product. Default: cosine_distance
</ParamField>

<ParamField path="index_arguments" type="Optional[dict]">
  Configuration parameters for the chosen index method.
  <Expandable title="Configuration Options">
    <ParamField path="HNSW Parameters">
      <ul>
        <li>m (int): Number of connections per element</li>
        <li>ef_construction (int): Size of the dynamic candidate list for construction</li>
      </ul>
    </ParamField>
    <ParamField path="IVFFlat Parameters">
      <ul>
        <li>n_lists (int): Number of clusters/inverted lists</li>
      </ul>
    </ParamField>
  </Expandable>
</ParamField>

<ParamField path="index_name" type="Optional[str]">
  Custom name for the index. If not provided, one will be auto-generated
</ParamField>

<ParamField path="concurrently" type="bool">
  Whether to create the index concurrently. Default: True
</ParamField>

#### Important Considerations

Vector index creation requires careful planning and consideration of your data and performance requirements. Keep in mind:

**Resource Intensive Process**
- Index creation can be CPU and memory intensive, especially for large datasets
- For HNSW indexes, memory usage scales with both dataset size and `m` parameter
- Consider creating indexes during off-peak hours for production systems

**Performance Tuning**
1. **HNSW Parameters:**
   - `m`: Higher values (16-64) improve search quality but increase memory usage and build time
   - `ef_construction`: Higher values increase build time and quality but have diminishing returns past 100
   - Recommended starting point: `m=16`, `ef_construction=64`

```python
# Example balanced configuration
client.create_vector_index(
    table_name="vectors",
    index_method="hnsw",
    index_measure="cosine_distance",
    index_arguments={
        "m": 16,                # Moderate connectivity
        "ef_construction": 64   # Balanced build time/quality
    },
    concurrently=True
)
```
**Pre-warming Required**
- **Important:** Newly created indexes require pre-warming to achieve optimal performance
- Initial queries may be slower until the index is loaded into memory
- The first several queries will automatically warm the index
- For production systems, consider implementing explicit pre-warming by running representative queries after index creation
- Without pre-warming, you may not see the expected performance improvements

**Best Practices**
1. Always use `concurrently=True` in production to avoid blocking other operations
2. Monitor system resources during index creation
3. Test index performance with representative queries before deploying
4. Consider creating indexes on smaller test datasets first to validate parameters

**Distance Measures**
Choose the appropriate measure based on your use case:
- `cosine_distance`: Best for normalized vectors (most common)
- `l2_distance`: Better for absolute distances
- `max_inner_product`: Optimized for dot product similarity

### List Vector Indices

List existing vector indices for a table:

```python
indices = client.list_vector_indices(table_name="vectors")
```

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="dict">
      The response containing the list of indices.
      ```bash
      {
        'indices': [
          {
            'name': 'ix_vector_cosine_ops_hnsw__20241021211541',
            'table': 'vectors',
            'method': 'hnsw',
            'measure': 'cosine_distance'
          },
          ...
        ]
      }
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>

<ParamField path="table_name" type="str">
  The table to list indices from. Options: vectors, entities_document, entities_collection, communities. Default: vectors
</ParamField>

### Delete Vector Index

Delete a vector index from a table:

```python
delete_response = client.delete_vector_index(
    index_name="ix_vector_cosine_ops_hnsw__20241021211541",
    table_name="vectors",
    concurrently=True
)
```

<AccordionGroup>
  <Accordion title="Response">
    <ResponseField name="response" type="dict">
      The response from the R2R system after deleting the vector index.
      ```bash
      {
        'message': 'Vector index deletion task queued successfully.',
        'task_id': '8e49efca-606d-422d-b73f-2d9e138661b6'
      }
      ```
    </ResponseField>
  </Accordion>
</AccordionGroup>

<ParamField path="index_name" type="str" required>
  Name of the index to delete
</ParamField>

<ParamField path="table_name" type="str">
  The table containing the index. Options: vectors, entities_document, entities_collection, communities. Default: vectors
</ParamField>

<ParamField path="concurrently" type="bool">
  Whether to delete the index concurrently. Default: True
</ParamField>


### Troubleshooting Common Issues

#### Ingestion Failures
- Check file permissions and paths
- Verify file formats are supported
- Ensure metadata length matches file_paths length
- Monitor memory usage for large files

#### Chunking Issues
- Large chunks (>1024 chars) may impact retrieval quality
- Small chunks (<64 chars) may lose context
- Adjust overlap for better context preservation

#### Vector Index Performance
- Monitor index creation time
- Check memory usage during creation
- Verify warm-up queries are representative
- Consider index rebuild if quality degrades
