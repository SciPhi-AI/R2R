import { Tabs } from 'nextra/components'

## Quick Installation

<Tabs items={['Installing with Pip ðŸ', 'Installing with Docker ðŸ³']}>
  <Tabs.Tab>
  Install R2R using `pip` to get started with minimal setup. This method will get you set up with the default configuration:

  ```bash
  # use the `'r2r[all]'` to download all required deps
  pip install r2r

  # setup env 
  export OPENAI_API_KEY=sk-...
  ```
  </Tabs.Tab>

  <Tabs.Tab>
  Docker makes it convenient to run R2R without managing your local environment.

  You'll first need to pull the latest R2R Docker image.

  If you plan to use hosted LLMs, such as OpenAI models, run:
  ```bash filename="bash" copy
  docker pull emrgntcmplxty/r2r:v2.0.15_slim
  ```

  This downloads the most recent Docker image and doesn't include optional dependencies for local LLMs which are quite large.

  If you plan to run local LLMs, pull the Docker image using the command:
  ```bash filename="bash" copy
  docker pull emrgntcmplxty/r2r:latest
  ```

  Be sure to set an OpenAI API key in your environment and then run the container with:

  ```bash filename="bash" copy
  docker run -d \
    --name r2r \
    --add-host=host.docker.internal:host-gateway \
    -p 8000:8000 \
    -e OPENAI_API_KEY=$OPENAI_API_KEY \
    emrgntcmplxty/r2r:latest
  ```

  This command starts the R2R container with the following options:

  - `--name r2r`: Assigns the name "r2r" to the container.
  - `--add-host=host.docker.internal:host-gateway`: Adds a host entry for the Docker host.
  - `-p 8000:8000`: Maps port 8000 of the container to port 8000 of the host.
  - `-e OPENAI_API_KEY=$OPENAI_API_KEY`: Pulls your OpenAI API key from your local enviornment for use in the container.
  - `emrgntcmplxty/r2r:latest`: Specifies the Docker image to use.
  </Tabs.Tab>
</Tabs>

## Full Installation

Full installation is largely meant to be used by developers who wish to extend the R2R framework.

<details>
<summary>1.&nbsp;<b>Install Poetry</b>: Ensure Poetry is installed.</summary>
Poetry manages the virtual environment and dependency resolution for your project, making it compatible with both existing `Pip` and `Conda` environments.
To install poetry, visit the [official Poetry website](https://python-poetry.org/docs/#installation) for the latest package and installation instructions or run the following command.
</details>

<details>
<summary>2.&nbsp;<b>Clone and Install Dependencies</b>: Get the project and its dependencies.</summary>
- Clone the project repository and navigate to the project directory:
  ```bash filename="bash" copy
  git clone git@github.com:SciPhi-AI/r2r.git
  cd r2r
  ```
- Install the project dependencies with Poetry:
  ```bash filename="bash" copy
  # See pyproject.toml for available extras
  # use "all" to include every optional dependency
  poetry install -E all
  ```
</details>

3. **Config Setup**: Create `.env` and `config.json`

<details>
<summary>4.&nbsp;<b>Configure Environment Variables</b>: Set up necessary `.env` configurations.</summary>
Copy the `.env.example` to `.env` and then apply your secrets. Afterwards, inspect the `config.json` and make any desired modifications.

```bash filename="bash" copy
vim .env # save env variables here

# Modify the config.json
vim config.json
```

We have several config options to run the project locally or at the cloud. At minimum, you'll need your OpenAI key secrets in your `.env` file for the project to work properly. For a fast setup, you can get started with a local Postgres db.

Visit this page for more information on [config setup](/deep-dive/config).
</details>


## Environment Setup

Below are examples of environment variables that can be configured to facilitate additional downstream functionality. The [provider guides](../providers/llms) have a more complete overview of different environment configurations.

<details>
<summary>Language Model Providers</summary>

#### OpenAI API Key

Used by default for embedding and LLM completions:

```bash filename="bash" copy
export OPENAI_API_KEY=sk-...
```

#### Other LLM Providers (Anthropic, Vertex AI, etc.)

Configure your environment for additional providers:

```bash filename="bash" copy
export ANTHROPIC_API_KEY=...
export VERTEX_API_KEY=...
# Add other provider keys as needed
```

</details>


<details>
<summary>VectorDB Providers</summary>

#### R2R Local VectorDB

R2R default selection - a simple SQLite-powered vector DB, optimal for lightweight workloads:

```bash filename="bash" copy
export LOCAL_DB_PATH=local.sqlite
```

#### pgvector

Better for larger scale workloads that benefit from relational data:

```bash filename="bash" copy
export POSTGRES_USER=your_user
export POSTGRES_PASSWORD=your_password
export POSTGRES_HOST=your_host
export POSTGRES_PORT=your_port
export POSTGRES_DBNAME=your_db
```
</details>

### Configuration and Customization

R2R provides extensive options to customize and configure your pipeline to suit specific needs. You can configure various providers through the `config.json` file and set environment variables as shown above to specify your vector database, embedding, language model, evaluation, and logging providers. Checkout the deep dive section of the docs for more visit this page for more information on [configuration](/deep-dive/configuring-your-pipeline) and [customization](/deep-dive/customizing-your-pipeline)
