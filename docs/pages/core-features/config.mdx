
During the example pipeline creation a default `config.json` is loaded and passed to the pipeline. It provides settings for the following services:

- Database provider
- LLM settings
- Embedding settings
- Parsing logic
- Evaluation provider
- and more.

The default values for the config are shown below. 

```json
{
  "database": {
    "provider": "local",
    "collection_name": "demo-v1-test"
  },
  "evals": {
    "provider": "deepeval",
    "frequency": 0.25
  },
  "embedding": {
    "provider": "openai",
    "model": "text-embedding-3-small",
    "dimension": 1536,
    "batch_size": 32
  },
  "text_splitter": {
    "chunk_size": 512,
    "chunk_overlap": 20
  },
  "language_model": {
    "provider": "litellm",
    "model": "gpt-4-0125-preview",
    "temperature": 0.1,
    "top_p": 0.9,
    "top_k": 128,
    "max_tokens_to_sample": 1024,
    "do_stream": false
  },
  "logging": {
    "provider": "local",
    "level": "INFO",
    "name": "r2r",
    "database": "demo_logs_v1"
  }
}
```
To launch the default pipeline with your own config, you may run with the following

```python

class E2EPipelineFactory:
    ...
    app = E2EPipelineFactory.create_pipeline(
        # override with your own config.json
        config_path=my_config.json,
    )
```
